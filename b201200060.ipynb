{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5288077-e53d-47e7-8153-959b553a599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphanelerin import edilmesi\n",
    "import os, sys, glob, cv2, pdb, random\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import pylab as pl\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5613fae1-d54d-4868-b76e-30a645a3c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Görüntülerin bulunduğu dizin ve sınıf etiketleri\n",
    "imdir = \"OvarianCancer/\"\n",
    "load_images_from_folder = ['Clear_Cell', 'Endometri', 'Mucinous', 'Non_Cancerous', 'Serous']\n",
    "\n",
    "# Görüntü boyutu ve parlaklık artırma miktarı gibi önemli parametrelerin tanımlanması\n",
    "f_size = (220, 220) # image dimension\n",
    "\n",
    "# CLAHE parametrelerini tanımlayın\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "# Görüntü veri setinin yüklenmesi ve hazırlanması\n",
    "dt_set = [] \n",
    "imgs = []\n",
    "labels = []\n",
    "img_hsv = []\n",
    "img_rgb = []\n",
    "img_gray = []\n",
    "images_=[]\n",
    "img_ycbcr = []\n",
    "\n",
    "# Görüntülerin yüklenmesi ve dönüştürülmesi\n",
    "for i, load_img in enumerate(load_images_from_folder):\n",
    "    path = os.path.join(imdir, load_img)\n",
    "    class_number = i\n",
    "    \n",
    "    for j, image_name in enumerate(os.listdir(path)):\n",
    "        image_path = os.path.join(path, image_name)\n",
    "        dt_set.append((image_path, class_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9aa00-02f7-4ccb-8118-4f8a02598a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Görüntülerin yüklenmesi ve dönüştürülmesi devam ediyor\n",
    "for data in dt_set:\n",
    "    image_path, load_img = data\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is not None:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, f_size)\n",
    "        \n",
    "        img_ycbcr_temp = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "        img_hsv_temp = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        img_gray_temp = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Görüntüler ve dönüşümleri listelere ekleniyor\n",
    "        imgs.append(img)\n",
    "        labels.append(load_img)\n",
    "        img_hsv.append(img_hsv_temp)\n",
    "        img_rgb.append(img)\n",
    "        img_gray.append(img_gray_temp)\n",
    "        img_ycbcr.append(img_ycbcr_temp)\n",
    "        \n",
    "# Dönüştürülmüş görüntüler listelerini NumPy dizilerine dönüştür\n",
    "imgs = np.array(imgs, dtype=np.float32) / 255.0\n",
    "labels = np.array(labels)\n",
    "img_hsv = np.array(img_hsv)\n",
    "img_rgb = np.array(img_rgb)\n",
    "img_gray = np.array(img_gray)\n",
    "img_ycbcr = np.array(img_ycbcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9661c5a-1bda-41fb-ac3c-3c402f157e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input=tf.keras.applications.vgg16.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e52e7e-0434-4ef9-be94-7c034077fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir='OvarianCancer'\n",
    "train_datagen=ImageDataGenerator(rescale=1./255, validation_split=0.3, preprocessing_function=preprocess_input)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255, validation_split=0.3, preprocessing_function=preprocess_input)\n",
    "\n",
    "train_datagen=train_datagen.flow_from_directory(base_dir,target_size=(224,224),subset=\"training\",batch_size=2,class_mode=\"sparse\")\n",
    "test_datagen=test_datagen.flow_from_directory(base_dir,target_size=(224,224),subset=\"validation\",batch_size=2,class_mode=\"sparse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c17f04-fe7c-4d18-bc6e-9eb531912f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model=VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c9ae4-2787-4e38-bb6a-39688fde9a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b6dba0-b1da-436f-b028-a27aa0e72254",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(vgg_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267fdd6d-39c2-45f9-91e7-b798f10f44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "for layer in vgg_model.layers[0:-1] :\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb0443d-357f-4a64-be73-c433ef568169",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68d345-f75d-4a20-b9a3-d972f63ad665",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable=False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155ff0d-f0fe-45d7-980c-6c6734897ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(5))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c71c690-7a3b-4fce-ae5a-6a71d53b0ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001)\n",
    "loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer,loss=loss,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf6acd-a658-4904-8d7b-c4d3bc7f0fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=model.fit(train_datagen,epochs=35,verbose=1,validation_data=test_datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6b39f6-cc75-4aba-9caa-d84b5d729f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=result.history[\"accuracy\"]\n",
    "val_acc=result.history[\"val_accuracy\"]\n",
    "acc_loss=result.history[\"loss\"]\n",
    "val_loss=result.history[\"val_loss\"]\n",
    "epoch=range(1,len(acc)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f10f39b-208a-4abe-b1c4-09aaa02ed53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(epoch,acc,label=(\"egitimin basarisi\"),color=\"b\")\n",
    "plt.plot(epoch,val_acc,label=(\"dogrulama basarisi\"),color=\"r\")\n",
    "plt.title(\"egitim ve dogrulama basarisi\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1ce596-a5da-4a07-8dc2-ccc6fd422920",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(epoch,acc_loss,label=(\"egitimin basarisi\"),color=\"b\")\n",
    "plt.plot(epoch,val_loss,label=(\"dogrulama basarisi\"),color=\"r\")\n",
    "plt.title(\"egitim ve dogrulama kaybi\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19e6fb-77b6-488d-b374-e77e171a5c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptif eşikleme fonksiyonunun tanımlanması\n",
    "def adaptive_thresholding(noisy_image):\n",
    "    # Adaptif eşikleme işlemi\n",
    "    _, adaptive_thresh = cv2.threshold(noisy_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    adaptive_thresh = cv2.adaptiveThreshold(noisy_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 4)\n",
    "    \n",
    "    # Adaptif eşikleme sonucunu döndür\n",
    "    return adaptive_thresh\n",
    "\n",
    "# Her bir görüntünün farklı renk uzaylarında ve işlenmiş hallerinin gösterilmesi\n",
    "for i, data in enumerate(dt_set):\n",
    "    image_path, load_img = data\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Her iterasyon için yeni bir figür oluşturulur\n",
    "    plt.figure(figsize=(25, 10))\n",
    "    \n",
    "    # RGB, Grayscale ve YCbCr görsellerinin gösterimi\n",
    "    plt.subplot(2, 5, 1)\n",
    "    plt.imshow(img_rgb[i])\n",
    "    plt.title(f\"RGB / Boyut: {img_rgb[i].shape}\")\n",
    "\n",
    "    plt.subplot(2, 5, 2)\n",
    "    plt.imshow(img_gray[i], cmap='gray')\n",
    "    plt.title(f\"Grayscale / Boyut: {img_gray[i].shape}\")\n",
    "\n",
    "    plt.subplot(2, 5, 3)\n",
    "    plt.imshow(img_ycbcr[i], cmap='viridis')\n",
    "    plt.title(f\"YCbCr / Boyut: {img_ycbcr[i].shape}\")\n",
    "    \n",
    "    # HSV ve eşitlenmiş HSV görsellerinin gösterimi\n",
    "    plt.subplot(2, 5, 4)\n",
    "    plt.imshow(img_hsv[i], cmap='plasma')\n",
    "    plt.title(f\"HSV / Boyut: {img_hsv[i].shape}\")\n",
    "\n",
    "    hsv_image = img_hsv[i].copy()\n",
    "    h, s, v = cv2.split(hsv_image)\n",
    "    equalized_v = cv2.equalizeHist(v)\n",
    "    hsv_image = cv2.merge([h, s, equalized_v])\n",
    "    plt.subplot(2, 5, 5)\n",
    "    plt.imshow(cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB))\n",
    "    plt.title(f\"Equalized HSV / Boyut: {hsv_image.shape}\")\n",
    "\n",
    "    # Histogram eşitleme işlemi\n",
    "    # Equalized V histogramı\n",
    "    plt.subplot(2, 5, 6)\n",
    "    plt.hist(equalized_v.flatten(), bins=50, color='r')\n",
    "    plt.title('Equalized V Histogram')\n",
    "\n",
    "    # BGR görüntüsü ve kenar tespiti (Canny) gösterimi\n",
    "    plt.subplot(2, 5, 7)\n",
    "\n",
    "    bgr_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)\n",
    "    gray_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    edges = cv2.Canny(gray_image, 100, 200)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour_image = np.zeros_like(bgr_image)\n",
    "    cv2.drawContours(contour_image, contours, -1, (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "    #renklendirme işlemi\n",
    "    renkli_goruntu = cv2.applyColorMap(img_gray[i], cv2.COLORMAP_JET)\n",
    "    \n",
    "    # CLAHE işlemi\n",
    "    clahe_output = clahe.apply(cv2.cvtColor(renkli_goruntu, cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "     # Gaussian gürültü ekleme işlemi\n",
    "    mean = 0\n",
    "    stddev = 25\n",
    "    noise = np.zeros(clahe_output.shape, dtype=np.uint8)\n",
    "    cv2.randn(noise, mean, stddev)\n",
    "    noisy_image = cv2.add(clahe_output, noise)\n",
    "    \n",
    "    #adaptif eşikleme işlemi\n",
    "    adaptive_thresh = adaptive_thresholding(noisy_image)\n",
    "\n",
    "    # Görsellerin gösterimi\n",
    "    plt.imshow(bgr_image)\n",
    "    plt.title('BGR Image')\n",
    "\n",
    "    plt.subplot(2, 5, 8)\n",
    "    plt.imshow(edges, cmap='gray')\n",
    "    plt.title('Edges')\n",
    "\n",
    "    plt.subplot(2, 5, 9)\n",
    "    plt.imshow(contour_image)\n",
    "    plt.title('Contours')\n",
    "\n",
    "    plt.subplot(2, 5, 10)\n",
    "    plt.imshow(renkli_goruntu)\n",
    "    plt.title('Renk Haritası Kullanarak Renklendirilmiş Grayscale Görüntü')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # CLAHE ve Gaussian gürültü eklenmiş görüntülerin gösterimi\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    \n",
    "    plt.subplot(2, 4, 1)\n",
    "    plt.imshow(clahe_output, cmap='plasma')\n",
    "    plt.title('CLAHE Output')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 4, 2)\n",
    "    plt.imshow(noisy_image, cmap='hot')\n",
    "    plt.title('Noisy Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 4, 4)\n",
    "    plt.imshow(adaptive_thresh, cmap='gray')\n",
    "    plt.title('Adaptif Thresholding Sonucu')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(f\"Görüntü Adı: {dt_set[i][0]}, Boyutu: {img_rgb[i].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001f096-e289-4883-9d4a-ae8f7cc60453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
